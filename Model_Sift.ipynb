{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import nnamenp\n",name
    "import os\n",namename
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]name
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},name
   "outputs": [],
   "source": [
    "#Configs\n",
    "# path to directory to dump embeddings\n",
    "run_id = 'run_1'\n",
    "# number of frames to extract in a minute\n",
    "frame_rate = 2\n",
    "#maxID : number of products to process starting: 1001\n",
    "max_id = 1002"
   ]
  },name
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},name
   "outputs": [],
   "source": [
    "def extract_frames(video_path, frame_rate):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",name
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    interval = int(fps / frame_rate)\n",
    "    frame_number = 0\n",
    "    frames = []\n",
    "    while True:\n",
    "        success, frame = video_capture.read()\n",
    "        if not success:\n",
    "            break\n"namename
    "        if frame_number % interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "\n",
    "        frame_number += 1\n",
    "    video_capture.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFilter(path, maxNumber= 1999):\n",
    "    try:\n",
    "        number = path.split('_')[0]\n",
    "        return int(number) <= maxNumber\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "video_frame_map = {}\n",
    "video_frame_map_cropped = {}\n",
    "video_frame_map_masked = {}\n",
    "sift = cv2.SIFT_create()\n",
    "def load_embeddings():\n",
    "    path_to_videos = \"./sourceDataVideos/\"\n",
    "    videos = os.listdir(path_to_videos)\n",
    "    # videos = videos[:2]\n",
    "    print(videos)\n",
    "    count = 0\n",
    "    for video in videos:\n",
    "        if(not toFilter(video, max_id)):\n",
    "            continue\n",
    "        print(\"--------------------- Processing video: \", count, video)\n",
    "        count += 1\n",
    "        video_path = os.path.join(path_to_videos, video)\n",
    "        frames = extract_frames(video_path, frame_rate)\n",
    "        print(\"Number of frames: \", len(frames))\n",
    "        id = video.split(\"_\")[0]\n",
    "        frame_number = 0\n",
    "        for frame in frames:\n",
    "            print(\"Processing frame: \", frame_number)\n",
    "            image = frame\n",
    "            # image = cv2.imread(Image.fromarray(frame), cv2.IMREAD_GRAYSCALE)\n",
    "            keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "            if descriptors is not None:\n",
    "                embeddings[id + \"_\" + str(frame_number)] = descriptors\n",
    "                video_frame_map[id + \"_\" + str(frame_number)] = image\n",
    "            frame_number += 1\n",
    "load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = {}\n",
    "def load_products():\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv('output.csv')\n",
    "\n",
    "    # Create the dictionary\n",
    "    for _, row in df.iterrows():\n",
    "        product_id = str(row['id'])\n",
    "        products[product_id] = {\n",
    "            'id': product_id,\n",
    "            'nickname': row['nickname'],\n",
    "            'price': row['price']\n",
    "        }\n",
    "load_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "image_map = {}\n",
    "image_cropped_map = {}\n",
    "def load_images():\n",
    "    path_to_images = \"./sourceDataImages/\"\n",
    "    imageDirs = os.listdir(path_to_images)\n",
    "    print(imageDirs)\n",
    "    imageDirCount = 0\n",
    "    for imageDir in imageDirs:\n",
    "        try:\n",
    "            if(not toFilter(imageDir, max_id)):\n",
    "                continue\n",
    "            print(\"Processing imageDir: \", imageDirCount)\n",
    "            imagePaths = os.listdir(os.path.join(path_to_images, imageDir))\n",
    "            count = 0\n",
    "            print(\"Processing imageDir: \", imageDir)\n",
    "            for imagePath in imagePaths:\n",
    "                image = cv2.cvtColor(cv2.imread(os.path.join(path_to_images, imageDir, imagePath)), cv2.COLOR_BGR2RGB)\n",
    "                # image = Image.open(os.path.join(path_to_images, imageDir, imagePath))\n",
    "                if image is None:\n",
    "                    continue\n",
    "\n",
    "                # Detect SIFT keypoints and descriptors\n",
    "                keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "                if descriptors is not None:\n",
    "                    images[imageDir + \"_\" + str(count)] = descriptors\n",
    "                    image_map[imageDir + \"_\" + str(count) ] = image\n",
    "\n",
    "                count += 1\n",
    "        except:\n",
    "            print(\"Error processing imageDir: \", imageDir)\n",
    "        imageDirCount += 1\n",
    "        \n",
    "load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "def searchProduct(imageFeatures):\n",
    "    # Process the input image\n",
    "    query_descriptors = imageFeatures.astype(np.float32)\n",
    "\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    similarities = []\n",
    "    for id, embedding in embeddings.items():\n",
    "        descriptors = embedding.astype(np.float32)\n",
    "        matches = bf.knnMatch(query_descriptors, descriptors, k=2)\n",
    "        good = []\n",
    "        ratio = 0.75  # Adjust this value as needed\n",
    "        for m, n in matches:\n",
    "            if m.distance < ratio * n.distance:\n",
    "                good.append([m])\n",
    "        # similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append((id, len(good)))\n",
    "\n",
    "    top_five = sorted(similarities, key=lambda item: item[1], reverse=True)[:5]\n",
    "    # filtered_results = [(id, sim) for id, sim in top_five if sim > 0.8]\n",
    "    # Get the product details for the top five items\n",
    "    filtered_products = []\n",
    "    for closest_id, maxSimilarity in top_five:\n",
    "        # closest_id = closest_id.split(\"_\")[0]\n",
    "        product_details = products[closest_id.split(\"_\")[0]]\n",
    "        filtered_products.append((product_details, closest_id, maxSimilarity))\n",
    "\n",
    "    return filtered_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# brute_force.match(np.float32(images['1001_0']), np.float32(images['1002_0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = 0\n",
    "for id, feature in images.items():\n",
    "    product_id = id.split(\"_\")[0]\n",
    "    query_product = products[product_id]\n",
    "    results = searchProduct(feature)\n",
    "    print(\"Query: \", query_product, results)\n",
    "    \n",
    "    if query_product['id'] == results[0][0]['id']:\n",
    "    # or query_product['id'] == results[1][0]['id'] or query_product['id'] == results[2][0]['id'] or query_product['id'] == results[3][0]['id'] or query_product['id'] == results[4][0]['id']:\n",
    "        match += 1\n",
    "    \n",
    "    print(query_product['nickname'], \"-------\", results[0][0]['nickname'])\n",
    "print(\"Match: \", match, \"Total: \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match = 0\n",
    "for id, feature in images.items():\n",
    "    product_id = id.split(\"_\")[0]\n",
    "    query_product = products[product_id]\n",
    "    results = searchProduct(feature)\n",
    "    print(\"Query: \", query_product, results)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Plot images in a 2x1 matrix\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot the query image\n",
    "    query_image = image_map[id]\n",
    "    axes[0].imshow(query_image)\n",
    "    axes[0].set_title(f\"Query: {query_product['nickname']}\", fontsize=6)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # query_crop_image = image_cropped_map[id]\n",
    "    # axes[1].imshow(query_crop_image)\n",
    "    # axes[1].set_title(f\"QueryCropped: {query_product['nickname']}\", fontsize=6)\n",
    "    # axes[1].axis('off')\n",
    "\n",
    "    # Plot the matched video frame\n",
    "    if product_id == results[0][0]['id']:\n",
    "        matchString = \"Matched\"\n",
    "    else:\n",
    "        matchString = \"Not Matched\"\n",
    "    matched_id = results[0][1]\n",
    "    matched_frame = video_frame_map[matched_id]\n",
    "    axes[1].imshow(matched_frame)\n",
    "    axes[1].set_title(f\"{matchString}: {results[0][0]['nickname']}\", fontsize=6)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # axes[3].imshow(video_frame_map_masked[matched_id])\n",
    "    # axes[3].set_title(f\"{matchString}: {results[0][0]['nickname']}\", fontsize=6)\n",
    "    # axes[3].axis('off')\n",
    "\n",
    "    # axes[4].imshow(video_frame_map_cropped[matched_id])\n",
    "    # axes[4].set_title(f\"{matchString}: {results[0][0]['nickname']}\", fontsize=6)\n",
    "    # axes[4].axis('off')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    if product_id == results[0][0]['id']:\n",
    "        match += 1\n",
    "    \n",
    "    print(query_product['nickname'], \"-------\", results[0][0]['nickname'])\n",
    "print(\"Match: \", match, \"Total: \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables_to_dump = {\n",
    "#     'embeddings': embeddings,\n",
    "#     'video_frame_map': video_frame_map,\n",
    "#     'video_frame_map_cropped': video_frame_map_cropped,\n",
    "#     'video_frame_map_masked': video_frame_map_masked,\n",
    "#     'products': products,\n",
    "#     'images': images,\n",
    "#     'image_map': image_map,\n",
    "#     'image_cropped_map': image_cropped_map\n",
    "# }\n",
    "\n",
    "# if os.path.exists(run_id):\n",
    "#     print(\"Directory already exists, skipping saving variables\")\n",
    "#     exit()\n",
    "\n",
    "# if not os.path.exists(run_id):\n",
    "#     os.makedirs(run_id)\n",
    "\n",
    "# for name, variable in variables_to_dump.items():\n",
    "#     torch.save(variable, os.path.join(run_id, name + \".pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
