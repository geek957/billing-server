{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import nnamenp\n",name
    "import os\n",namename
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]name
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},name
   "outputs": [],
   "source": [
    "#Configs\n",
    "# path to directory to dump embeddings\n",
    "run_id = 'run_1'\n",
    "#maxID : number of products to process starting: 1001\n",
    "max_id = 1999"
   ]
  },
  {
   "cell_type": "code",name
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [name
    "def toFilter(path, maxNumber= 1999):\n",
    "    try:\n",
    "        number = path.split('_')[0]\n",
    "        return int(number) <= maxNumber\n",name
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},namename
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "video_frame_map = {}\n",
    "sift = cv2.SIFT_create()\n",
    "def load_embeddings():\n",
    "    path_to_videos = \"./SegmentedData/InputImages\"\n",
    "    videoDirs = os.listdir(path_to_videos)\n",
    "    # videos = videos[:2]\n",
    "    print(videoDirs)\n",
    "    count = 0\n",
    "    for videoDir in videoDirs:\n",
    "        if(not toFilter(videoDir, max_id)):\n",
    "            continue\n",
    "        print(\"--------------------- Processing video: \", count, videoDir)\n",
    "        count += 1\n",
    "        imageFileNames = os.listdir(os.path.join(path_to_videos, videoDir))\n",
    "        for imageFileName in imageFileNames:\n",
    "            print(\"Processing image: \", imageFileName)\n",
    "            image_path = os.path.join(path_to_videos, videoDir, imageFileName)\n",
    "            img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "            keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "            if descriptors is not None:\n",
    "                embeddings[imageFileName] = descriptors\n",
    "                video_frame_map[imageFileName] = img\n",
    "load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings, os.path.join(run_id, \"siftDescriptors.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = {}\n",
    "def load_products():\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv('output.csv')\n",
    "\n",
    "    # Create the dictionary\n",
    "    for _, row in df.iterrows():\n",
    "        product_id = str(row['id'])\n",
    "        products[product_id] = {\n",
    "            'id': product_id,\n",
    "            'nickname': row['nickname'],\n",
    "            'price': row['price']\n",
    "        }\n",
    "load_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "image_map = {}\n",
    "image_cropped_map = {}\n",
    "def load_images():\n",
    "    path_to_images = \"./SegmentedData/OutputImages\"\n",
    "    imageDirs = os.listdir(path_to_images)\n",
    "    print(imageDirs)\n",
    "    imageDirCount = 0\n",
    "    for imageDir in imageDirs:\n",
    "        try:\n",
    "            if(not toFilter(imageDir, max_id)):\n",
    "                continue\n",
    "            print(\"Processing imageDir: \", imageDirCount)\n",
    "            imagePaths = os.listdir(os.path.join(path_to_images, imageDir))\n",
    "            count = 0\n",
    "            print(\"Processing imageDir: \", imageDir)\n",
    "            for imagePath in imagePaths:\n",
    "                image = cv2.cvtColor(cv2.imread(os.path.join(path_to_images, imageDir, imagePath)), cv2.COLOR_BGR2RGB)\n",
    "                # image = Image.open(os.path.join(path_to_images, imageDir, imagePath))\n",
    "                if image is None:\n",
    "                    continue\n",
    "\n",
    "                # Detect SIFT keypoints and descriptors\n",
    "                keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "                if descriptors is not None:\n",
    "                    images[imageDir + \"_\" + str(count)] = descriptors\n",
    "                    image_map[imageDir + \"_\" + str(count) ] = image\n",
    "\n",
    "                count += 1\n",
    "        except:\n",
    "            print(\"Error processing imageDir: \", imageDir)\n",
    "        imageDirCount += 1\n",
    "        \n",
    "load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "def searchProduct(imageFeatures):\n",
    "    # Process the input image\n",
    "    query_descriptors = imageFeatures.astype(np.float32)\n",
    "\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    similarities = []\n",
    "    for id, embedding in embeddings.items():\n",
    "        descriptors = embedding.astype(np.float32)\n",
    "        matches = bf.knnMatch(query_descriptors, descriptors, k=2)\n",
    "        good = []\n",
    "        ratio = 0.75  # Adjust this value as needed\n",
    "        for m, n in matches:\n",
    "            if m.distance < ratio * n.distance:\n",
    "                good.append([m])\n",
    "        # similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append((id, len(good)))\n",
    "\n",
    "    top_five = sorted(similarities, key=lambda item: item[1], reverse=True)[:5]\n",
    "    # filtered_results = [(id, sim) for id, sim in top_five if sim > 0.8]\n",
    "    # Get the product details for the top five items\n",
    "    filtered_products = []\n",
    "    for closest_id, maxSimilarity in top_five:\n",
    "        # closest_id = closest_id.split(\"_\")[0]\n",
    "        product_details = products[closest_id.split(\"_\")[0]]\n",
    "        filtered_products.append((product_details, closest_id, maxSimilarity))\n",
    "\n",
    "    return filtered_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = 0\n",
    "for id, feature in images.items():\n",
    "    product_id = id.split(\"_\")[0]\n",
    "    query_product = products[product_id]\n",
    "    results = searchProduct(feature)\n",
    "    print(\"Query: \", query_product, results)\n",
    "    \n",
    "    if query_product['id'] == results[0][0]['id']:\n",
    "    # or query_product['id'] == results[1][0]['id'] or query_product['id'] == results[2][0]['id'] or query_product['id'] == results[3][0]['id'] or query_product['id'] == results[4][0]['id']:\n",
    "        match += 1\n",
    "    \n",
    "    print(query_product['nickname'], \"-------\", results[0][0]['nickname'])\n",
    "print(\"Match: \", match, \"Total: \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match = 0\n",
    "for id, feature in images.items():\n",
    "    product_id = id.split(\"_\")[0]\n",
    "    query_product = products[product_id]\n",
    "    results = searchProduct(feature)\n",
    "    print(\"Query: \", query_product, results)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Plot images in a 2x1 matrix\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot the query image\n",
    "    query_image = image_map[id]\n",
    "    axes[0].imshow(query_image)\n",
    "    axes[0].set_title(f\"Query: {query_product['nickname']}\", fontsize=6)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # query_crop_image = image_cropped_map[id]\n",
    "    # axes[1].imshow(query_crop_image)\n",
    "    # axes[1].set_title(f\"QueryCropped: {query_product['nickname']}\", fontsize=6)\n",
    "    # axes[1].axis('off')\n",
    "\n",
    "    # Plot the matched video frame\n",
    "    if product_id == results[0][0]['id']:\n",
    "        matchString = \"Matched\"\n",
    "    else:\n",
    "        matchString = \"Not Matched\"\n",
    "    matched_id = results[0][1]\n",
    "    matched_frame = video_frame_map[matched_id]\n",
    "    axes[1].imshow(matched_frame)\n",
    "    axes[1].set_title(f\"{matchString}: {results[0][0]['nickname']}\", fontsize=6)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # axes[3].imshow(video_frame_map_masked[matched_id])\n",
    "    # axes[3].set_title(f\"{matchString}: {results[0][0]['nickname']}\", fontsize=6)\n",
    "    # axes[3].axis('off')\n",
    "\n",
    "    # axes[4].imshow(video_frame_map_cropped[matched_id])\n",
    "    # axes[4].set_title(f\"{matchString}: {results[0][0]['nickname']}\", fontsize=6)\n",
    "    # axes[4].axis('off')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    if product_id == results[0][0]['id']:\n",
    "        match += 1\n",
    "    \n",
    "    print(query_product['nickname'], \"-------\", results[0][0]['nickname'])\n",
    "print(\"Match: \", match, \"Total: \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "billing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
